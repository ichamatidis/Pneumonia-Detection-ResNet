# -*- coding: utf-8 -*-
"""pneumonia

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mFW_soeNCs6bN89WUKSRkonL15mrqCaK
"""

import cv2
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from keras.utils import to_categorical
from sklearn.utils import shuffle
import os
import keras
from tensorflow.python.client import device_lib
!pip install -U -q PyDrive
from google.colab import drive

#Mount drive
drive.mount('/content/gdrive')

path = "/content/gdrive/My Drive/Colab Notebooks/Pneumonia/chest_xray"
train_path = path + "/train/"
test_path = path + "/test/"

#Train set
#Calculate normal images
subdirs, dirs, files = os.walk(train_path+'NORMAL').__next__()
m_normal = len(files)
print("There are ",m_normal," normal images")

#Calculate Pneumonia images
subdirs, dirs, files = os.walk(train_path+'PNEUMONIA').__next__()
m_pneum = len(files)
print("There are ",m_pneum," pnuemonia images")

train_filenames = []
train_labels = np.zeros((m_normal+m_normal,1))

counter = 0
def normal_pneumonia_labels(path, train_filenames, train_labels, counter):
    for subdir, dirs, files in os.walk(train_path+'NORMAL'):
        for file in files:
            train_filenames.append(train_path+'NORMAL/'+file)
            train_labels[counter, 0] = 0
            counter = counter + 1

def viral_bacterial_labels(path, train_filenames, train_labels, counter):
    for subdir, dirs, files in os.walk(train_path+'PNEUMONIA'):
        for file in files:
            if(counter<2*m_normal):
            train_filenames.append(train_path+'PNEUMONIA/'+file)
            if("virus" in file):
                train_labels[counter, 0] = 0
            else:
                train_labels[counter, 0] = 1
            counter = counter + 
# Depending on the experiment run normal_penumonia or viral_bacterial
normal_pneumonia_labels(train_path, train_filenames, train_labels, counter)
# OR
viral_bacterial_labels(train_path, train_filenames, train_labels, counter)

train_labels = to_categorical(train_labels)
train_labels

filenames_shuffled, labels_shuffled = shuffle(train_filenames, train_labels)
x_train, x_val, y_train, y_val = train_test_split(filenames_shuffled, labels_shuffled, test_size=0.15, random_state=0)

# Read test set
subdirs, dirs, files = os.walk(test_path+'NORMAL').__next__()
m_normal = len(files)
print("There are ",m_normal," normal images")

subdirs, dirs, files = os.walk(test_path+'PNEUMONIA').__next__()
m_pneum = len(files)
print("There are ",m_pneum," pnuemonia images")

# Test set
test_filenames = []
test_labels = np.zeros((m_normal+m_pneum,1))
# Depending on the experiment run normal_penumonia or viral_bacterial
normal_pneumonia_labels(test_path, train_filenames, train_labels, counter)
# OR
viral_bacterial_labels(test_path, train_filenames, train_labels, counter)
counter = 0


print(len(test_filenames))
test_labels = to_categorical(test_labels)

class My_Custom_Generator(keras.utils.Sequence) :
    def __init__(self, image_filenames, labels, batch_size) :
        self.image_filenames = image_filenames
        self.labels = labels
        self.batch_size = batch_size
    def __len__(self) :
        return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int)
    def __getitem__(self, idx) :
        batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]
        batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]
        return np.array([
            cv2.resize(cv2.imread(str(file_name)), (224, 224))
               for file_name in batch_x])/255.0, np.array(batch_y)

batch_size = 32

my_training_batch_generator = My_Custom_Generator(x_train, y_train, batch_size)
my_validation_batch_generator = My_Custom_Generator(x_val,y_val, batch_size)
my_test_batch_generator = My_Custom_Generator(test_filenames, test_labels, batch_size)

# from keras.applications.resnet50 import ResNet50
from keras.applications.vgg16 import VGG16
# from keras.applications.resnet50 import resnet50

from keras.preprocessing import image
# from keras.applications.resnet50 import preprocess_input, decode_predictions
from keras.applications.vgg16 import preprocess_input, decode_predictions

from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,AveragePooling2D
from keras.models import Sequential,Model,load_model

#Define last layers of resnet
base_model = VGG16(weights= "imagenet", include_top=False, input_shape= (224,224,3))
new_model = base_model.output
new_model = AveragePooling2D(pool_size=(4, 4))(new_model)
new_model = Flatten(name="flatten")(new_model)
new_model = Dense(64, activation="relu")(new_model)
new_model = Dropout(0.4)(new_model)
new_model = Dense(2, activation="softmax")(new_model)
model = Model(inputs=base_model.input, outputs=new_model)

model.compile(optimizer="adam", loss='categorical_crossentropy', metrics=['accuracy'])

import math
from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler
def step_decay(epoch):
    initial_lrate = 0.001
    drop = 0.4
    epochs_drop = 15.0
    lrate = initial_lrate * math.pow(drop,  
            math.floor((1+epoch)/epochs_drop))
    
    if (lrate < 4e-5):
        lrate = 4e-5
      
    print('Changing learning rate to {}'.format(lrate))
    return lrate
lrate = LearningRateScheduler(step_decay)

earlystopper = EarlyStopping(monitor='val_accuracy', patience=10,
                             verbose=1, restore_best_weights=True)
checkpointer = ModelCheckpoint("model.h5", monitor='val_accuracy', verbose=1, save_best_only=True)

history = model.fit_generator(generator=my_training_batch_generator,
                   steps_per_epoch = int(len(train_filenames) // batch_size),
                   epochs = 60,
                   verbose = 1,
                   validation_data = my_validation_batch_generator,
                   validation_steps =int(len(x_val)/batch_size),
                   callbacks=[earlystopper,checkpointer,lrate]
                   )
# model.save('model.h5')`

import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.0, 1.2])
plt.legend(loc='lower right')

model = load_model("/content/gdrive/My Drive/Colab Notebooks/Pneumonia/NvP_vgg16.h5.h5")
results = model.evaluate_generator(generator=my_test_batch_generator,verbose=1)
print("test_loss= ",results[0]," test_acc= ",results[1])
# model.summary()

# model.save("/content/gdrive/My Drive/Colab Notebooks/Pneumonia/NvP_vgg16.h5")

# model = load_model("/content/gdrive/My Drive/Colab Notebooks/Pneumonia/NvP")

# model.summary()

from keras import backend as K
def get_class_activation_map(path,idx) :
    
  out_path = "/content/gdrive/My Drive/"
  img_path =  path
  img = cv2.imread(img_path)
  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
  # plt.imsave(out_path+str(idx)+".jpeg",cv2.resize(img,(600,600)))
  img = cv2.resize(img, (224, 224))
  img = np.expand_dims(img,axis=0)
  
  predict = model.predict(img)
  target_class = np.argmax(predict[0])
  last_conv = model.get_layer('block5_conv3')
  grads =K.gradients(model.output[:,target_class],last_conv.output)[0]
  pooled_grads = K.mean(grads,axis=(0,1,2))
  iterate = K.function([model.input],[pooled_grads,last_conv.output[0]])
  pooled_grads_value,conv_layer_output = iterate([img])
  # for i in range(512):
  #     conv_layer_output[:,:,i] *= pooled_grads_value[i]
  heatmap = np.mean(conv_layer_output,axis=-1)
  for x in range(heatmap.shape[0]):
      for y in range(heatmap.shape[1]):
          heatmap[x,y] = np.max(heatmap[x,y])
  heatmap = np.maximum(heatmap,0)
  heatmap /= np.max(heatmap)
  img_gray = cv2.cvtColor(img[0], cv2.COLOR_BGR2GRAY)
  upsample = cv2.resize(heatmap, (224,224))
  
  title=' '
  if(target_class==0):
    title='Healthy_'+str(idx)
  else:
    title='Pneumonia_'+str(idx)
  out = cv2.resize(img_gray*upsample,(600,600))
  plt.figure()
  plt.title(title)
  plt.imshow(out)
  # plt.imsave(out_path+title+"_"+"_img_gray.jpeg",cv2.resize(img_gray,(600,600)))
  # plt.imsave(out_path+title+"_"+"_heatmap.jpeg",out)

get_class_activation_map(test_filenames[0],0)
get_class_activation_map(test_filenames[1],1)
get_class_activation_map(test_filenames[2],2)
get_class_activation_map(test_filenames[3],3)
get_class_activation_map(test_filenames[4],4)
get_class_activation_map(test_filenames[3],5)